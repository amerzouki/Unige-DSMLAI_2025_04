{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau neuronal convolutif (CNN)\n",
    "\n",
    "Cet exercice illustre la formation d'un réseau de neurones convolutifs (CNN) pour classer les images CIFAR. On utilise l'API séquentielle Keras. La création et la formation de votre modèle ne prendront que quelques lignes de code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Télécharger et préparer le jeu de données CIFAR10\n",
    "\n",
    "L'ensemble de données CIFAR10 contient 60 000 images couleur dans 10 classes, avec 6 000 images dans chaque classe. L'ensemble de données est divisé en 50 000 images d'entraînement et 10 000 images de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier les données\n",
    "\n",
    "Pour vérifier que l'ensemble de données semble correct, traçons les 25 premières images de l'ensemble d'apprentissage et affichons le nom de la classe sous chaque image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer la base convolutive\n",
    "Les 6 lignes de code ci-dessous définissent la base convolutive en utilisant un modèle commun : une pile de couches Conv2D et MaxPooling2D .\n",
    "\n",
    "En entrée, un CNN prend des tenseurs de forme (image_height, image_width, color_channels), en ignorant la taille du lot. Si vous débutez avec ces dimensions, color_channels fait référence à (R,G,B). Dans cet exemple, vous allez configurer votre CNN pour traiter les entrées de forme (32, 32, 3), qui est le format des images CIFAR. Vous pouvez le faire en passant l'argument input_shape à votre première couche.\n",
    "\n",
    "[Documentation de la classe Sequential](https://keras.io/api/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Affichez l'architecture de votre modèle jusqu'à présent.\n",
    "Utilisez pour cela la méthode `.summary()``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter des couches denses sur le dessus\n",
    "Pour compléter le modèle, vous allez alimenter le dernier tenseur de sortie de la base convolutive (de forme (4, 4, 64)) dans une couche dense pour effectuer la classification. \n",
    "\n",
    "Les couches denses prennent des vecteurs en entrée (qui sont 1D), tandis que la sortie actuelle est un tenseur 3D. \n",
    "\n",
    "* Tout d'abord, vous allez aplatir (ou dérouler) la sortie 3D en 1D, puis \n",
    "* ajouter un calques Dense par-dessus. \n",
    "* CIFAR a 10 classes de sortie, vous utilisez donc une couche Dense finale avec 10 sorties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résumé du réseau montre que (4, 4, 64) les sorties ont été aplaties en vecteurs de forme (1024) avant de passer par deux couches Dense.\n",
    "\n",
    "### Compiler et entraîner le modèle\n",
    "\n",
    "**Notes**\n",
    "\n",
    "> [Documentation pour les fonctions de cout](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class)\n",
    "\n",
    "\n",
    "**QUESTIONS**\n",
    "\n",
    "Quelle est la taille par défaut d'un Batch (i.e., nombre d'échantillons par mise-à-jour du gradient) lorsqu'on entraine le modèle? ([Model.fit(...)](https://keras.io/api/models/model_training_apis/)) \n",
    "\n",
    "Pour 50000 images d'entrainement (pour chaque Epoch), combien de fois mettons à jour les gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer le modèle\n",
    "\n",
    "Visualisez l'évolution de l'Accuracy en fonction des Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "Visualisez l'évolution de la foction de perte en fonction des Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE ICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**\n",
    "\n",
    "Qu'observez-vous?\n",
    "\n",
    "Essayez d'entrainer le modèle plus longtemps (augmentez le nombre d'Epoch)\n",
    "\n",
    "Que se passe-t-il si on entraine trop longtemps le modèle?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des Erreurs de Classification\n",
    "#### Matrice de Confusion Multi-Classes\n",
    "\n",
    "**Instruction**: Créer la [matrice de confusion multi-classes](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#Prédire les classes pour les images de test\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_labels.reshape(-1)\n",
    "\n",
    "# Créer la matrice de confusion\n",
    "## CODE ICI\n",
    "conf_matrix = None\n",
    "\n",
    "# Afficher la matrice de confusion sous forme de heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies classes')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.savefig('matrice_confusion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction:** Créez et affichez le [rapport de classification](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) incluant le Précision, le Rappel et le F1-Score pour chacune des 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher quelques métriques supplémentaires (Précision, Rappel, F1-score)\n",
    "print(\"Rapport de classification :\\n\")\n",
    "## CODE ICI\n",
    "\n",
    "# Analyser les erreurs de classification\n",
    "# Identifier les exemples mal classés\n",
    "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
    "\n",
    "# Sélectionner un échantillon aléatoire d'exemples mal classés\n",
    "sample_size = min(25, len(misclassified_indices))\n",
    "sample_indices = np.random.choice(misclassified_indices, sample_size, replace=False)\n",
    "\n",
    "# Afficher les exemples mal classés\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(test_images[idx])\n",
    "    plt.title(f\"Vraie: {class_names[true_classes[idx]]}\\nPrédite: {class_names[predicted_classes[idx]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('erreurs_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculer les taux d'erreur par classe\n",
    "error_rates = []\n",
    "for i in range(10):\n",
    "    class_indices = np.where(true_classes == i)[0]\n",
    "    class_errors = np.sum(predicted_classes[class_indices] != i)\n",
    "    error_rate = class_errors / len(class_indices)\n",
    "    error_rates.append(error_rate)\n",
    "\n",
    "# Afficher les taux d'erreur par classe\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(class_names, error_rates, color='salmon')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Taux d\\'erreur')\n",
    "plt.title('Taux d\\'erreur par classe')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('taux_erreur_par_classe.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Analyser les confusions les plus fréquentes\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            confusion_pairs.append((i, j, conf_matrix[i, j]))\n",
    "\n",
    "# Trier par nombre de confusions (du plus grand au plus petit)\n",
    "confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Afficher les 10 confusions les plus fréquentes\n",
    "print(\"\\nLes 10 confusions les plus fréquentes :\")\n",
    "for true_class, pred_class, count in confusion_pairs[:10]:\n",
    "    print(f\"Vraie classe: {class_names[true_class]}, Prédite comme: {class_names[pred_class]}, Nombre: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Améliorations techniques possibles\n",
    "1. **Architecture plus profonde**: Ajout de couches supplémentaires pour capturer des caractéristiques plus complexes\n",
    "2. **Dropout**: Désactive aléatoirement des neurones pour réduire le surapprentissage\n",
    "3. **Augmentation de données**: Rotation, zoom, décalage et retournement horizontal pour améliorer la généralisation\n",
    "4. **Optimisation des hyperparamètres**:\n",
    "   - Taille de batch optimisée (64)\n",
    "   - Taux d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "[Convolutional Neural Network (CNN)](https://www.tensorflow.org/tutorials/images/cnn)\n",
    "\n",
    "[Computer Vision - TenserFlow Tutorials](https://www.tensorflow.org/tutorials/images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
